{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk.data\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Flatten, Dense, Conv1D, MaxPooling1D, GlobalMaxPool1D, SpatialDropout1D, \\\n",
    "                          UpSampling1D, LSTM, RepeatVector, TimeDistributed, GRU, Bidirectional, concatenate\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "pd.set_option('max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('../../Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1060651400131</td>\n",
       "      <td>Woman_Limited_El_Corte_Inglés</td>\n",
       "      <td>moda mujer abrigo masculino textura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1060651400180</td>\n",
       "      <td>Woman_Limited_El_Corte_Inglés</td>\n",
       "      <td>moda mujer abrigo doble faz cinturon tono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051056400107</td>\n",
       "      <td>Woman_El_Corte_Inglés</td>\n",
       "      <td>moda mujer abrigo largo antelina woman corte_ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019350401147</td>\n",
       "      <td>Lloyd's</td>\n",
       "      <td>moda mujer abrigo chaqueta termica efecto cortavientos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019353400229</td>\n",
       "      <td>Lloyd's</td>\n",
       "      <td>moda mujer abrigo parka algodon capucha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                          brand  \\\n",
       "0  1060651400131  Woman_Limited_El_Corte_Inglés   \n",
       "1  1060651400180  Woman_Limited_El_Corte_Inglés   \n",
       "2  1051056400107          Woman_El_Corte_Inglés   \n",
       "3  1019350401147                        Lloyd's   \n",
       "4  1019353400229                        Lloyd's   \n",
       "\n",
       "                                                     text  \n",
       "0                     moda mujer abrigo masculino textura  \n",
       "1               moda mujer abrigo doble faz cinturon tono  \n",
       "2     moda mujer abrigo largo antelina woman corte_ingles  \n",
       "3  moda mujer abrigo chaqueta termica efecto cortavientos  \n",
       "4                 moda mujer abrigo parka algodon capucha  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'Texto_PreProcesado_v1.csv', sep = ';', index_col = False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Sentences\n",
    "\n",
    "- Initialize tokenizer with num_words = MAX_NB_WORDS (200K). i.e. The tokenizer will perform a word count, sorted by number of occurences in descending order and pick top N words, 200K in this case \n",
    "- Use tokenizer's texts_to_sequences method to convert text to array of integers.\n",
    "- The arrays obtained from previous step might not be of uniform length, use pad_sequences method to obtain arrays with length equal to MAX_SEQUENCE_LENGTH (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 30_000 #decided by cumsum wordcount plot (Script 01)\n",
    "MAX_SEQUENCE_LENGTH = 24 #decided by max words in a product (Script 00)\n",
    "EMBEDDING_DIM = 100 #Same dim as our W2V embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = data['text']\n",
    "all_text = all_text.drop_duplicates (keep = False)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, )\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "data_sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "data_vec = pad_sequences(data_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49418 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    1,    3,   94,\n",
       "       2461, 1432])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets load our Custom Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWV = Word2Vec.load(\"word2vec_model_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Keras Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enric\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "C:\\Users\\Enric\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "word_vectors = modelWV.wv\n",
    "vocabulary_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in modelWV:\n",
    "        embedding_matrix[i] = modelWV[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.rand(1, EMBEDDING_DIM)[0]\n",
    "            \n",
    "\n",
    "del(word_vectors)\n",
    "\n",
    "embedding_layer = Embedding(input_dim = vocabulary_size,\n",
    "                            output_dim = EMBEDDING_DIM,\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            weights=[embedding_matrix],\n",
    "                            name='w2v_embedding',\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "w2v_embedding (Embedding)    (None, 24, 100)           4941900   \n",
      "=================================================================\n",
      "Total params: 4,941,900\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,941,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204812/204812 [==============================] - 7s 36us/step\n"
     ]
    }
   ],
   "source": [
    "data_embedded = model.predict(data_vec, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Dense Layer based, low quantity of params and easy to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_i = Input(shape=(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM))\n",
    "encoded_h1 = Dense(128, activation='relu')(input_i)\n",
    "encoded_h2 = Dense(64, activation='relu')(encoded_h1)\n",
    "encoded_h3 = Dense(32, activation='relu')(encoded_h2)\n",
    "encoded_h4 = Dense(16, activation='relu')(encoded_h3)\n",
    "#encoded_h5 = Dense(8, activation='relu')(encoded_h4)\n",
    "\n",
    "latent = Dense(8, activation='relu', name = 'ENCODER')(encoded_h4)\n",
    "\n",
    "#decoder_h1 = Dense(8, activation='relu')(latent)\n",
    "decoder_h2 = Dense(16, activation='relu')(latent)\n",
    "decoder_h3 = Dense(32, activation='relu')(decoder_h2)\n",
    "decoder_h4 = Dense(64, activation='relu')(decoder_h3)\n",
    "decoder_h5 = Dense(128, activation='relu')(decoder_h4)\n",
    "\n",
    "output = Dense(EMBEDDING_DIM, activation='relu')(decoder_h5)\n",
    "\n",
    "autoencoder = Model(input_i,output)\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "204812/204812 [==============================] - 146s 715us/step - loss: 0.8201\n",
      "Epoch 2/3\n",
      "204812/204812 [==============================] - 144s 704us/step - loss: 0.7912\n",
      "Epoch 3/3\n",
      "204812/204812 [==============================] - 143s 697us/step - loss: 0.7859\n",
      "Wall time: 7min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b912402240>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit(data_embedded,data_embedded,epochs=3,\n",
    "            batch_size=64, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "### The more complex the model is the better?\n",
    "\n",
    "- Basic LSTM Layer based\n",
    "\n",
    "- Take nothe that we are compressing more the encoder layer, instead of LENTGH = 192 in dense approach, now we are compressing to LENGHT = 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 24, 100)           91600     \n",
      "=================================================================\n",
      "Total params: 208,848\n",
      "Trainable params: 208,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_i = Input(shape=(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM))\n",
    "\n",
    "x1 = LSTM(128, return_sequences=False, name = 'ENCODER')(input_i)\n",
    "x2 = RepeatVector(24)(x1)\n",
    "x3 = LSTM (100, return_sequences=True)(x2)\n",
    "\n",
    "autoencoder = Model(inputs = input_i, outputs = x3)\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "204812/204812 [==============================] - 448s 2ms/step - loss: 0.8621\n",
      "Epoch 2/3\n",
      "204812/204812 [==============================] - 445s 2ms/step - loss: 0.7974\n",
      "Epoch 3/3\n",
      "204812/204812 [==============================] - 451s 2ms/step - loss: 0.7787\n",
      "Wall time: 22min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ee2118e898>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit(data_embedded, data_embedded ,epochs=3,\n",
    "            batch_size=32, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "- Lets give it another chance to LSTM Layer based but now we will give the LSTM 2 inputs in order to fit better to the order word changes.\n",
    "\n",
    "- Take nothe that we are compressing more the encoder layer, instead of LENTGH = 192 in dense approach, now we are compressing to LENGHT = 128 as we did in Model 2\n",
    "\n",
    "- Also we have less training params so we will train the autoencoder faster than in Model2 Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 24, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 24, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           42240       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           42240       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ENCODER (Concatenate)           (None, 128)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 24, 128)      0           ENCODER[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 24, 100)      91600       repeat_vector_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 176,080\n",
      "Trainable params: 176,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_i1 = Input(shape=(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM))\n",
    "input_i2 = Input(shape=(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM))\n",
    "\n",
    "am1 = LSTM(64, return_sequences=False)(input_i1)\n",
    "am2 = LSTM(64, return_sequences=False)(input_i2)\n",
    "\n",
    "decoder = concatenate([am1, am2], name = 'ENCODER')\n",
    "\n",
    "x2 = RepeatVector(24)(decoder)\n",
    "x3 = LSTM(100, return_sequences=True)(x2)\n",
    "\n",
    "autoencoder = Model([input_i1, input_i2], x3)\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "204812/204812 [==============================] - 513s 3ms/step - loss: 0.8630\n",
      "Epoch 2/3\n",
      "204812/204812 [==============================] - 485s 2ms/step - loss: 0.7953\n",
      "Epoch 3/3\n",
      "204812/204812 [==============================] - 507s 2ms/step - loss: 0.7780\n",
      "Wall time: 25min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156096b5710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit([data_embedded,data_embedded], data_embedded ,epochs=3,\n",
    "            batch_size=32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('ENCODER').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_json = encoder.to_json()\n",
    "#with open(\"encoder_text_V1.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "encoder.save('encoder_text_V1.h5')\n",
    "#encoder.save_weights('weights_encoder_text_V1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file = open('encoder_text_V1.json', 'r')\n",
    "#encoder = json_file.read()\n",
    "#json_file.close()\n",
    "#encoder = model_from_json(encoder)\n",
    "encoder = load_model('encoder_text_V1.h5')\n",
    "#encoder.load_weights('weights_encoder_text_V1.h5', by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = encoder.get_layer('ENCODER').output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 24, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 24, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           42240       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           42240       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ENCODER (Concatenate)           (None, 128)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 84,480\n",
      "Trainable params: 84,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                    001004742503321\n",
       "brand                                                                                           Miele\n",
       "text     electrodomestico horno placa campana extractoras cocina isla da touch control obsidian black\n",
       "Name: 58000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[58000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = data_embedded[58000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204812, 24, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data_embedded.copy()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "codes = encoder.predict([X_test, X_test])\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_code = encoder.predict([query.reshape(1,MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), query.reshape(1,MAX_SEQUENCE_LENGTH,EMBEDDING_DIM)])\n",
    "query_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204812, 128)\n",
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "codes = codes.reshape(-1, shape)\n",
    "print(codes.shape)\n",
    "query_code = query_code.reshape(1, shape)\n",
    "print(query_code.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the KNN to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_neigh = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neigh).fit(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(query_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 24, 100)\n"
     ]
    }
   ],
   "source": [
    "closest_sent = X_test[indices]\n",
    "closest_sent = closest_sent.reshape(-1,MAX_SEQUENCE_LENGTH,EMBEDDING_DIM); \n",
    "print(closest_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                    001004742503321\n",
       "brand                                                                                           Miele\n",
       "text     electrodomestico horno placa campana extractoras cocina isla da touch control obsidian black\n",
       "Name: 58000, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[58000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                                    001004742503321\n",
      "brand                                                                                           Miele\n",
      "text     electrodomestico horno placa campana extractoras cocina isla da touch control obsidian black\n",
      "Name: 58000, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                  001004742503305\n",
      "brand                                                                                         Miele\n",
      "text     electrodomestico horno placa campana extractoras cocina isla da touch control havana brown\n",
      "Name: 57998, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                   001004742400155\n",
      "brand                                                                                                         Franke\n",
      "text     electrodomestico horno placa campana extractoras cocina telescopicas telescopica mega flex ftc v2 velocidad\n",
      "Name: 150416, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                   001004742400163\n",
      "brand                                                                                                         Franke\n",
      "text     electrodomestico horno placa campana extractoras cocina telescopicas telescopica mega flex ftc v2 velocidad\n",
      "Name: 150417, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                          001004741029179\n",
      "brand                                                                                                                 Balay\n",
      "text     electrodomestico horno placa campana extractoras cocina telescopicas telescopica 3bt890b control deslizante blanco\n",
      "Name: 57248, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                      001004742500301\n",
      "brand                                                                                            Franke\n",
      "text     electrodomestico horno placa campana extractoras cocina isla tube ftu xs panel control digital\n",
      "Name: 150418, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                               001004742401039\n",
      "brand                                                                                                       Cata\n",
      "text     electrodomestico horno placa campana extractoras cocina telescopicas telescopica tf wh nivel extraccion\n",
      "Name: 99744, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                   001004741134201\n",
      "brand                                                                                                     Electrolux\n",
      "text     electrodomestico horno placa campana extractoras cocina decorativas decorativa efb90680bx sensor humo vapor\n",
      "Name: 57790, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                                 001004741138574\n",
      "brand                                                                                                                         Cata\n",
      "text     electrodomestico horno placa campana extractoras cocina decorativas decorativa legend temporizador desconexion automatica\n",
      "Name: 150244, dtype: object\n",
      "--------------------------------------------------\n",
      "id                                                                                                                 001004741138566\n",
      "brand                                                                                                                         Cata\n",
      "text     electrodomestico horno placa campana extractoras cocina decorativas decorativa legend temporizador desconexion automatica\n",
      "Name: 150245, dtype: object\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mis_indices = indices.tolist()[0]\n",
    "for i in range(n_neigh):\n",
    "    print (data.loc[mis_indices[i]])\n",
    "    print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
