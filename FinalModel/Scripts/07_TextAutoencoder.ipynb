{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Autoencoder\n",
    "\n",
    "In this notebook we generate the text autoencoder in order to reduce the dimension of our text vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk.data\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Flatten, Dense, Conv1D, MaxPooling1D, GlobalMaxPool1D, SpatialDropout1D, \\\n",
    "                          UpSampling1D, LSTM, RepeatVector, TimeDistributed, GRU, Bidirectional, concatenate, \\\n",
    "                          GlobalAveragePooling1D\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "pd.set_option('max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('../Data/')\n",
    "path_models = os.path.join('../Models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A28233506</td>\n",
       "      <td>Woman Limited El Corte Inglés</td>\n",
       "      <td>abrigo masculino textura mujer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A29054782</td>\n",
       "      <td>Woman Limited El Corte Inglés</td>\n",
       "      <td>abrigo doble faz mujer cinturon tono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A27354432</td>\n",
       "      <td>Woman El Corte Inglés</td>\n",
       "      <td>abrigo largo antelina mujer woman corte_ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28302706</td>\n",
       "      <td>Lloyd's</td>\n",
       "      <td>chaqueta termica mujer efecto cortavientos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A27435502</td>\n",
       "      <td>Lloyd's</td>\n",
       "      <td>parka algodon mujer capucha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id                          brand  \\\n",
       "0  A28233506  Woman Limited El Corte Inglés   \n",
       "1  A29054782  Woman Limited El Corte Inglés   \n",
       "2  A27354432          Woman El Corte Inglés   \n",
       "3  A28302706                        Lloyd's   \n",
       "4  A27435502                        Lloyd's   \n",
       "\n",
       "                                             text  \n",
       "0                  abrigo masculino textura mujer  \n",
       "1            abrigo doble faz mujer cinturon tono  \n",
       "2  abrigo largo antelina mujer woman corte_ingles  \n",
       "3      chaqueta termica mujer efecto cortavientos  \n",
       "4                     parka algodon mujer capucha  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'Texto_PreProcesado.csv', sep = ';', index_col = False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Sentences\n",
    "\n",
    "- Initialize tokenizer with num_words = MAX_NB_WORDS (200K). i.e. The tokenizer will perform a word count, sorted by number of occurences in descending order and pick top N words, 200K in this case \n",
    "- Use tokenizer's texts_to_sequences method to convert text to array of integers.\n",
    "- The arrays obtained from previous step might not be of uniform length, use pad_sequences method to obtain arrays with length equal to MAX_SEQUENCE_LENGTH (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 30_000 #decided by cumsum wordcount plot (Script 01)\n",
    "MAX_SEQUENCE_LENGTH = 24 #decided by max words in a product (Script 00)\n",
    "EMBEDDING_DIM = 100 #Same dim as our W2V embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].astype(str)\n",
    "all_text = data['text']\n",
    "all_text = all_text.drop_duplicates (keep = False)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, )\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "data_sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "data_vec = pad_sequences(data_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48964 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,  173, 9335,\n",
       "       1135,    1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets load our Custom Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWV = Word2Vec.load(path_models + \"word2vec_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Keras Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enric\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "C:\\Users\\enric\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "word_vectors = modelWV.wv\n",
    "vocabulary_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in modelWV:\n",
    "        embedding_matrix[i] = modelWV[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.rand(1, EMBEDDING_DIM)[0]\n",
    "            \n",
    "\n",
    "del(word_vectors)\n",
    "\n",
    "embedding_layer = Embedding(input_dim = vocabulary_size,\n",
    "                            output_dim = EMBEDDING_DIM,\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            weights=[embedding_matrix],\n",
    "                            name='w2v_embedding',\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\enric\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "w2v_embedding (Embedding)    (None, 24, 100)           4896500   \n",
      "=================================================================\n",
      "Total params: 4,896,500\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,896,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204812, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204812/204812 [==============================] - 7s 34us/step\n"
     ]
    }
   ],
   "source": [
    "data_embedded = model.predict(data_vec, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Dense Layer based, low quantity of params and easy to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embedding_39 (Embedding)     (None, 24, 100)           4941900   \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 24, 128)           12928     \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 24, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 24, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 24, 16)            528       \n",
      "_________________________________________________________________\n",
      "ENCODER (Dense)              (None, 24, 8)             136       \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 24, 16)            144       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 24, 32)            544       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 24, 64)            2112      \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 24, 128)           8320      \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 24)                73752     \n",
      "=================================================================\n",
      "Total params: 5,050,700\n",
      "Trainable params: 108,800\n",
      "Non-trainable params: 4,941,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_i = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "\n",
    "text_embedding = Embedding(*embedding_matrix.shape, weights = [embedding_matrix], trainable = False)(input_i)\n",
    "\n",
    "encoded_h1 = Dense(128, activation='relu')(text_embedding)\n",
    "encoded_h2 = Dense(64, activation='relu')(encoded_h1)\n",
    "encoded_h3 = Dense(32, activation='relu')(encoded_h2)\n",
    "encoded_h4 = Dense(16, activation='relu')(encoded_h3)\n",
    "#encoded_h5 = Dense(8, activation='relu')(encoded_h4)\n",
    "\n",
    "latent = Dense(8, activation='relu', name = 'ENCODER')(encoded_h4)\n",
    "\n",
    "#decoder_h1 = Dense(8, activation='relu')(latent)\n",
    "decoder_h2 = Dense(16, activation='relu')(latent)\n",
    "decoder_h3 = Dense(32, activation='relu')(decoder_h2)\n",
    "decoder_h4 = Dense(64, activation='relu')(decoder_h3)\n",
    "decoder_h5 = Dense(128, activation='relu')(decoder_h4)\n",
    "\n",
    "#output = Dense(EMBEDDING_DIM, activation='relu')(decoder_h5)\n",
    "glob = Flatten()(decoder_h5)\n",
    "output = Dense(MAX_SEQUENCE_LENGTH, activation = 'relu')(glob)\n",
    "\n",
    "autoencoder = Model(input_i, output)\n",
    "\n",
    "autoencoder.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['acc'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "204812/204812 [==============================] - 83s 403us/step - loss: 950483.3912 - acc: 0.5859\n",
      "Epoch 2/10\n",
      "204812/204812 [==============================] - 76s 371us/step - loss: 498594.6927 - acc: 0.6698\n",
      "Epoch 3/10\n",
      "204812/204812 [==============================] - 81s 395us/step - loss: 420760.2395 - acc: 0.7096\n",
      "Epoch 4/10\n",
      "204812/204812 [==============================] - 78s 379us/step - loss: 366811.3258 - acc: 0.7451\n",
      "Epoch 5/10\n",
      "204812/204812 [==============================] - 87s 425us/step - loss: 329093.0555 - acc: 0.7792\n",
      "Epoch 6/10\n",
      "204812/204812 [==============================] - 87s 427us/step - loss: 280425.0401 - acc: 0.8029\n",
      "Epoch 7/10\n",
      "204812/204812 [==============================] - 78s 382us/step - loss: 258836.2753 - acc: 0.8189\n",
      "Epoch 8/10\n",
      "204812/204812 [==============================] - 79s 384us/step - loss: 242508.3749 - acc: 0.8300\n",
      "Epoch 9/10\n",
      "204812/204812 [==============================] - 81s 398us/step - loss: 229794.6558 - acc: 0.8401\n",
      "Epoch 10/10\n",
      "204812/204812 [==============================] - 74s 360us/step - loss: 219910.0323 - acc: 0.8489\n",
      "Wall time: 13min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c927561d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit(data_vec, data_vec, epochs=10,\n",
    "            batch_size=128, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "### The more complex the model is the better?\n",
    "\n",
    "- Basic LSTM Layer based\n",
    "\n",
    "- Take nothe that we are compressing more the encoder layer, instead of LENTGH = 192 in dense approach, now we are compressing to LENGHT = 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embedding_35 (Embedding)     (None, 24, 100)           4941900   \n",
      "_________________________________________________________________\n",
      "ENCODER (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "repeat_vector_15 (RepeatVect (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 24, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 24, 49419)         6375051   \n",
      "=================================================================\n",
      "Total params: 11,565,783\n",
      "Trainable params: 6,623,883\n",
      "Non-trainable params: 4,941,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_i = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "\n",
    "text_embedding = Embedding(*embedding_matrix.shape, weights = [embedding_matrix], trainable = False)(input_i)\n",
    "\n",
    "x1 = LSTM(128, return_sequences=False, name = 'ENCODER')(text_embedding)\n",
    "x2 = RepeatVector(24)(x1)\n",
    "x3 = LSTM (24, return_sequences=False)(x2)\n",
    "\n",
    "autoencoder = Model(inputs = input_i, outputs = x3)\n",
    "autoencoder.compile(optimizer = 'rmsprop', loss = 'mse' , metrics = ['acc'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "204812/204812 [==============================] - 376s 2ms/step - loss: 4348197.7735 - acc: 0.0036\n",
      "Epoch 2/3\n",
      "204812/204812 [==============================] - 385s 2ms/step - loss: 4348194.9891 - acc: 0.0027\n",
      "Epoch 3/3\n",
      "204812/204812 [==============================] - 408s 2ms/step - loss: 4348195.0703 - acc: 0.0027\n",
      "Wall time: 19min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c52d90978>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit(data_vec, data_vec ,epochs=3,\n",
    "            batch_size=64, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "- Lets give it another chance to LSTM Layer based but now we will give the LSTM 2 inputs in order to fit better to the order word changes.\n",
    "\n",
    "- Take nothe that we are compressing more the encoder layer, instead of LENTGH = 192 in dense approach, now we are compressing to LENGHT = 128 as we did in Model 2\n",
    "\n",
    "- Also we have less training params so we will train the autoencoder faster than in Model2 Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 24, 100)      4896500     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 24, 100)      4896500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           42240       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           42240       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ENCODER (Concatenate)           (None, 128)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 24, 128)      0           ENCODER[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 24)           14688       repeat_vector_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 9,892,168\n",
      "Trainable params: 99,168\n",
      "Non-trainable params: 9,793,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_i1 = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "input_i2 = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "\n",
    "text_embedding1 = Embedding(*embedding_matrix.shape, weights = [embedding_matrix], trainable = False)(input_i1)\n",
    "text_embedding2 = Embedding(*embedding_matrix.shape, weights = [embedding_matrix], trainable = False)(input_i2)\n",
    "\n",
    "am1 = LSTM(64, return_sequences=False)(text_embedding1)\n",
    "am2 = LSTM(64, return_sequences=False)(text_embedding2)\n",
    "\n",
    "decoder = concatenate([am1, am2], name = 'ENCODER')\n",
    "\n",
    "x2 = RepeatVector(24)(decoder)\n",
    "x3 = LSTM(24, return_sequences=False)(x2)\n",
    "\n",
    "autoencoder = Model([input_i1, input_i2], x3)\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mse', metrics = ['acc'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\enric\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      " 27136/204812 [==>...........................] - ETA: 3:47 - loss: 4052401.7070 - acc: 0.0273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder.fit([data_vec, data_vec], data_vec ,epochs=3,\n",
    "            batch_size=64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('ENCODER').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(path_models + 'encoder_text.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enric\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model(path_models + 'encoder_text.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = encoder.get_layer('ENCODER').output_shape[1] * encoder.get_layer('ENCODER').output_shape[2]\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embedding_39 (Embedding)     (None, 24, 100)           4941900   \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 24, 128)           12928     \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 24, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 24, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 24, 16)            528       \n",
      "_________________________________________________________________\n",
      "ENCODER (Dense)              (None, 24, 8)             136       \n",
      "=================================================================\n",
      "Total params: 4,965,828\n",
      "Trainable params: 23,928\n",
      "Non-trainable params: 4,941,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                        A24259977\n",
       "brand                    El Corte Inglés\n",
       "text       set taza te buga corte_ingles\n",
       "Name: 70000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = data_vec[70000]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204812, 24)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data_vec.copy()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204812, 24, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = encoder.predict(X_test)\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204812, 24, 8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_code = encoder.predict([query.reshape(1, MAX_SEQUENCE_LENGTH)])\n",
    "query_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204812, 192)\n",
      "(1, 192)\n"
     ]
    }
   ],
   "source": [
    "codes = codes.reshape(-1, shape)\n",
    "print(codes.shape)\n",
    "query_code = query_code.reshape(1, shape)\n",
    "print(query_code.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the KNN to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neigh = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neigh).fit(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(query_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 24)\n",
      "(10, 24)\n"
     ]
    }
   ],
   "source": [
    "closest_sent = X_test[indices]\n",
    "print(closest_sent.shape)\n",
    "closest_sent = closest_sent.reshape(n_neigh, MAX_SEQUENCE_LENGTH); \n",
    "print(closest_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                                       A26136146\n",
       "brand                                             Miele\n",
       "text       campana isla da touch control obsidian black\n",
       "Name: 58000, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[58000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                        A24259977\n",
      "brand                    El Corte Inglés\n",
      "text       set taza te buga corte_ingles\n",
      "Name: 70000, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                                    A13099826\n",
      "brand                                El Corte Inglés\n",
      "text       set accesorio venir winegift corte_ingles\n",
      "Name: 103310, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                              A24346780\n",
      "brand                          El Corte Inglés\n",
      "text       set copa helado ancona corte_ingles\n",
      "Name: 70523, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                                  A27996468\n",
      "brand                              El Corte Inglés\n",
      "text       reloj mesa plateado bayona corte_ingles\n",
      "Name: 66172, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                          A24259995\n",
      "brand                      El Corte Inglés\n",
      "text       set taza cafe cali corte_ingles\n",
      "Name: 70002, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                              A24346774\n",
      "brand                          El Corte Inglés\n",
      "text       set copa helado rimini corte_ingles\n",
      "Name: 70520, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                              A24346782\n",
      "brand                          El Corte Inglés\n",
      "text       set copa helado sirolo corte_ingles\n",
      "Name: 70524, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                                         A13997585\n",
      "brand                                     El Corte Inglés\n",
      "text       set silla comedor tapizadas dolva corte_ingles\n",
      "Name: 101988, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                                 A26198390\n",
      "brand                             El Corte Inglés\n",
      "text       cojin detalle lurex polux corte_ingles\n",
      "Name: 102655, dtype: object\n",
      "--------------------------------------------------\n",
      "item_id                                 A24317008\n",
      "brand                             El Corte Inglés\n",
      "text       cojin raya borla aquarius corte_ingles\n",
      "Name: 68465, dtype: object\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mis_indices = indices.tolist()[0]\n",
    "for i in range(n_neigh):\n",
    "    print (data.loc[mis_indices[i]])\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
